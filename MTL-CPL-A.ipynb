{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbd2b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T21:49:34.091269Z",
     "iopub.status.busy": "2023-11-18T21:49:34.090966Z",
     "iopub.status.idle": "2023-11-18T21:49:49.285781Z",
     "shell.execute_reply": "2023-11-18T21:49:49.284975Z"
    },
    "papermill": {
     "duration": 15.203594,
     "end_time": "2023-11-18T21:49:49.288584",
     "exception": false,
     "start_time": "2023-11-18T21:49:34.084990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(1)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "#import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23c235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T21:49:49.302345Z",
     "iopub.status.busy": "2023-11-18T21:49:49.301779Z",
     "iopub.status.idle": "2023-11-18T21:49:49.308654Z",
     "shell.execute_reply": "2023-11-18T21:49:49.307761Z"
    },
    "papermill": {
     "duration": 0.015327,
     "end_time": "2023-11-18T21:49:49.310637",
     "exception": false,
     "start_time": "2023-11-18T21:49:49.295310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_layer(tensor):\n",
    "    return tensor[0] + tensor[1]\n",
    "\n",
    "def mul_layer(tensor):\n",
    "    return tensor[0] * tensor[1]\n",
    "\n",
    "def div_layer(tensor):\n",
    "    return tensor[0] / tensor[1]\n",
    "\n",
    "def sub_layer(tensor):\n",
    "    return tensor[0] - tensor[1]\n",
    "\n",
    "def neg_layer(tensor):\n",
    "    return -tensor\n",
    "\n",
    "def cos_layer(tensor):\n",
    "    return tf.math.cos(tensor)\n",
    "\n",
    "def sin_layer(tensor):\n",
    "    return tf.math.sin(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe4fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T21:49:49.322381Z",
     "iopub.status.busy": "2023-11-18T21:49:49.322044Z",
     "iopub.status.idle": "2023-11-18T21:50:06.584573Z",
     "shell.execute_reply": "2023-11-18T21:50:06.583774Z"
    },
    "papermill": {
     "duration": 17.271086,
     "end_time": "2023-11-18T21:50:06.586747",
     "exception": false,
     "start_time": "2023-11-18T21:49:49.315661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature extraction from left image\n",
    "\n",
    "\n",
    "left_img = Input(shape = (150,150,3), name=\"left_image\")\n",
    "\n",
    "# feature extraction from right image\n",
    "right_img = Input(shape = (150,150,3), name=\"right_image\")\n",
    "\n",
    "left_phi_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=left_img, input_shape=(150,150,3))\n",
    "for layer in left_phi_model.layers:\n",
    "  layer._name = layer._name+\"f1_base\"\n",
    "\n",
    "left_phi_features = left_phi_model.output\n",
    "left_flat = Flatten(name='left-phi-flattened')(left_phi_features)\n",
    "\n",
    "right_phi_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=right_img, input_shape=(150,150,3))\n",
    "for layer in right_phi_model.layers:\n",
    "  layer._name = layer._name+\"f2_base\"\n",
    "\n",
    "right_phi_features = right_phi_model.output\n",
    "right_flat = Flatten(name='right-phi-flattened')(right_phi_features)\n",
    "\n",
    "concat = concatenate([left_flat, right_flat])\n",
    "\n",
    "# fx\n",
    "dense_1 = Dense(120, activation = 'relu')(concat)\n",
    "dense_2 = Dense(84, activation = 'relu')(dense_1)\n",
    "pred_fx = Dense(1, name='fx')(dense_2)\n",
    "\n",
    "# fy\n",
    "dense_3 = Dense(120, activation = 'relu')(concat)\n",
    "dense_4 = Dense(84, activation = 'relu')(dense_3)\n",
    "pred_fy = Dense(1, name='fy')(dense_4)\n",
    "\n",
    "# u0\n",
    "dense_5 = Dense(120, activation = 'relu')(concat)\n",
    "dense_6 = Dense(84, activation = 'relu')(dense_5)\n",
    "pred_u0 = Dense(1, name='u0')(dense_6)\n",
    "\n",
    "# v0\n",
    "dense_7 = Dense(120, activation = 'relu')(concat)\n",
    "dense_8 = Dense(84, activation = 'relu')(dense_7)\n",
    "pred_v0 = Dense(1, name='v0')(dense_8)\n",
    "\n",
    "# baseline\n",
    "dense_9 = Dense(120, activation = 'relu')(concat)\n",
    "dense_10 = Dense(84, activation = 'relu')(dense_9)\n",
    "pred_baseline = Dense(1, name='baseline')(dense_10)\n",
    "\n",
    "# tx\n",
    "dense_11 = Dense(120, activation = 'relu')(concat)\n",
    "dense_12 = Dense(84, activation = 'relu')(dense_11)\n",
    "pred_x = Dense(1, name='x')(dense_12)\n",
    "\n",
    "# ty\n",
    "dense_13 = Dense(120, activation = 'relu')(concat)\n",
    "dense_14 = Dense(84, activation = 'relu')(dense_13)\n",
    "pred_y = Dense(1, name='y')(dense_14)\n",
    "\n",
    "# tz\n",
    "dense_15 = Dense(120, activation = 'relu')(concat)\n",
    "dense_16 = Dense(84, activation = 'relu')(dense_15)\n",
    "pred_z = Dense(1, name='z')(dense_16)\n",
    "\n",
    "# pitch\n",
    "dense_17 = Dense(120, activation = 'relu')(concat)\n",
    "dense_18 = Dense(84, activation = 'relu')(dense_17)\n",
    "pred_pitch = Dense(1, name='pitch')(dense_18)\n",
    "\n",
    "# u\n",
    "dense_19 = Dense(120, activation = 'relu')(concat)\n",
    "dense_20 = Dense(84, activation = 'relu')(dense_19)\n",
    "pred_u = Dense(1, name='u')(dense_20)\n",
    "\n",
    "# v\n",
    "dense_21 = Dense(120, activation = 'relu')(concat)\n",
    "dense_22 = Dense(84, activation = 'relu')(dense_21)\n",
    "pred_v = Dense(1, name='v')(dense_22)\n",
    "\n",
    "# disparity\n",
    "dense_23 = Dense(120, activation = 'relu')(concat)\n",
    "dense_24 = Dense(84, activation = 'relu')(dense_23)\n",
    "pred_disparity = Dense(1, name='disparity')(dense_24)\n",
    "\n",
    "# w_xcam\n",
    "#dense_25 = Dense(120, activation = 'relu')(concat)\n",
    "#dense_26 = Dense(84, activation = 'relu')(dense_25)\n",
    "#w_xcam = Dense(1, name='w_xcam', activation = 'sigmoid')(dense_26)\n",
    "\n",
    "# w_ycam\n",
    "#dense_27 = Dense(120, activation = 'relu')(concat)\n",
    "#dense_28 = Dense(84, activation = 'relu')(dense_27)\n",
    "#w_ycam = Dense(1, name='w_ycam', activation = 'sigmoid')(dense_28)\n",
    "\n",
    "# w_zcam\n",
    "#dense_29 = Dense(120, activation = 'relu')(concat)\n",
    "#dense_30 = Dense(84, activation = 'relu')(dense_29)\n",
    "#w_zcam = Dense(1, name='w_zcam', activation = 'sigmoid')(dense_30)\n",
    "\n",
    "# w_xworld\n",
    "dense_31 = Dense(120, activation = 'relu')(concat)\n",
    "dense_32 = Dense(84, activation = 'relu')(dense_31)\n",
    "w_xworld = Dense(1, name='w_xworld', activation = 'sigmoid')(dense_32)\n",
    "\n",
    "# w_yworld\n",
    "dense_33 = Dense(120, activation = 'relu')(concat)\n",
    "dense_34 = Dense(84, activation = 'relu')(dense_33)\n",
    "w_yworld = Dense(1, name='w_yworld', activation = 'sigmoid')(dense_34)\n",
    "\n",
    "# w_zworld\n",
    "dense_35 = Dense(120, activation = 'relu')(concat)\n",
    "dense_36 = Dense(84, activation = 'relu')(dense_35)\n",
    "w_zworld = Dense(1, name='w_zworld', activation = 'sigmoid')(dense_36)\n",
    "\n",
    "\n",
    "# xCam = (self.intrinsic.fx * self.extrinsic.baseline) / disparity\n",
    "mul_1 = Lambda(mul_layer)([pred_fx, pred_baseline])\n",
    "xCam = Lambda(div_layer)([mul_1, pred_disparity])\n",
    "#xCam = Lambda(mul_layer, name='xCam')([xCam, w_xcam])\n",
    "\n",
    "# yCam = - (xCam / self.intrinsic.fx) * (u - self.intrinsic.u0)\n",
    "div_1 = Lambda(div_layer)([xCam, pred_fx])\n",
    "sub_1 = Lambda(sub_layer)([pred_u, pred_u0])\n",
    "yCam = Lambda(mul_layer)([Lambda(neg_layer)(div_1), sub_1])\n",
    "#yCam = Lambda(mul_layer, name='yCam')([yCam, w_ycam])\n",
    "\n",
    "# zCam = (xCam / self.intrinsic.fy) * (self.intrinsic.v0 - v)\n",
    "div_2 = Lambda(div_layer)([xCam, pred_fy])\n",
    "sub_2 = Lambda(sub_layer)([pred_v0, pred_v])\n",
    "zCam = Lambda(mul_layer)([div_2, sub_2])\n",
    "#zCam = Lambda(mul_layer, name='zCam')([zCam, w_zcam])\n",
    "\n",
    "# Y = yCam + self.extrinsic.y\n",
    "pred_yWorld = Lambda(add_layer)([yCam, pred_y])\n",
    "pred_yWorld = Lambda(mul_layer, name='yWorld')([pred_yWorld, w_yworld])\n",
    "\n",
    "# X = xCam * math.cos(self.extrinsic.pitch) + zCam * math.sin(self.extrinsic.pitch) + self.extrinsic.x\n",
    "mul_2 = Lambda(mul_layer)([xCam, Lambda(cos_layer)(pred_pitch)])\n",
    "mul_3 = Lambda(mul_layer)([zCam, Lambda(sin_layer)(pred_pitch)])\n",
    "add_1 = Lambda(add_layer)([mul_2, mul_3])\n",
    "pred_xWorld = Lambda(add_layer)([add_1, pred_x])\n",
    "pred_xWorld = Lambda(mul_layer, name='xWorld')([pred_xWorld, w_xworld])\n",
    "\n",
    "# Z = - xCam * math.sin(self.extrinsic.pitch) + zCam * math.cos(self.extrinsic.pitch) + self.extrinsic.z\n",
    "mul_4 = Lambda(mul_layer)([Lambda(neg_layer)(xCam), Lambda(sin_layer)(pred_pitch)])\n",
    "mul_5 = Lambda(mul_layer)([zCam, Lambda(cos_layer)(pred_pitch)])\n",
    "add_2 = Lambda(add_layer)([mul_4, mul_5])\n",
    "pred_zWorld = Lambda(add_layer)([add_2, pred_z])\n",
    "pred_zWorld = Lambda(mul_layer, name='zWorld')([pred_zWorld, w_zworld])\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[left_img, right_img], outputs=[pred_fx, pred_fy, pred_u0, pred_v0, pred_baseline, pred_disparity, pred_x, pred_y, pred_z, pred_pitch, pred_xWorld,pred_yWorld,pred_zWorld])\n",
    "\n",
    "# set output types\n",
    "target1 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target2 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target3 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target4 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target5 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target6 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target7 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target8 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target9 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target10 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target11 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target12 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target13 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "\n",
    "# get model summary\n",
    "#model.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"mae\", target_tensors=[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12, target13],optimizer=optimizers.legacy.Adam(lr=learning_rate));\n",
    "#plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe707a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T21:50:06.618506Z",
     "iopub.status.busy": "2023-11-18T21:50:06.618247Z",
     "iopub.status.idle": "2023-11-18T21:50:06.842990Z",
     "shell.execute_reply": "2023-11-18T21:50:06.842050Z"
    },
    "papermill": {
     "duration": 0.233678,
     "end_time": "2023-11-18T21:50:06.845157",
     "exception": false,
     "start_time": "2023-11-18T21:50:06.611479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_path = 'path/'\n",
    "Fx = np.load(data_path+\"Fx.npy\", mmap_mode='r')\n",
    "Fy = np.load(data_path+\"Fy.npy\", mmap_mode='r')\n",
    "U0 = np.load(data_path+\"U0.npy\", mmap_mode='r')\n",
    "V0 = np.load(data_path+\"V0.npy\", mmap_mode='r')\n",
    "Disparity = np.load(data_path+\"Disparity.npy\", mmap_mode='r')\n",
    "Tx = np.load(data_path+\"Tx.npy\", mmap_mode='r')\n",
    "Ty = np.load(data_path+\"Ty.npy\", mmap_mode='r')\n",
    "Tz = np.load(data_path+\"Tz.npy\", mmap_mode='r')\n",
    "Baseline = np.load(data_path+\"Baseline.npy\", mmap_mode='r')\n",
    "Pitch = np.load(data_path+\"Pitch.npy\", mmap_mode='r')\n",
    "X = np.load(data_path+\"X.npy\", mmap_mode='r')\n",
    "Y = np.load(data_path+\"Y.npy\", mmap_mode='r')\n",
    "Z = np.load(data_path+\"Z.npy\", mmap_mode='r')\n",
    "Left_images = np.load(data_path+\"left_img.npy\", mmap_mode='r')\n",
    "Right_images = np.load(data_path+\"right_img.npy\", mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490ed40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T21:50:07.024393Z",
     "iopub.status.busy": "2023-11-18T21:50:07.024045Z",
     "iopub.status.idle": "2023-11-19T06:01:43.263466Z",
     "shell.execute_reply": "2023-11-19T06:01:43.262463Z"
    },
    "papermill": {
     "duration": 29496.273766,
     "end_time": "2023-11-19T06:01:43.288715",
     "exception": false,
     "start_time": "2023-11-18T21:50:07.014949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "#from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "model_name = 'model_multi_class/'\n",
    "SAVE = \"CPL_A/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "# Save\n",
    "output_folder = SAVE + model_name\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_log = output_folder + \"Log/\"\n",
    "if not os.path.exists(output_log):\n",
    "    os.makedirs(output_log)\n",
    "\n",
    "output_weight = output_folder + \"Best/\"\n",
    "if not os.path.exists(output_weight):\n",
    "    os.makedirs(output_weight)\n",
    "\n",
    "\n",
    "input_shape = (150, 150, 3)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_log)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('CPL_a_training_100.log')\n",
    "\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=output_weight + \"weights_{epoch:02d}_{val_loss:.2f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[Left_images[:int(len(Left_images)*0.7)], Right_images[:int(len(Left_images)*0.7)]],\n",
    "    y=[Fx[:int(len(Left_images)*0.7)], Fy[:int(len(Left_images)*0.7)], U0[:int(len(Left_images)*0.7)], V0[:int(len(Left_images)*0.7)], Baseline[:int(len(Left_images)*0.7)], Disparity[:int(len(Left_images)*0.7)], Tx[:int(len(Left_images)*0.7)], Ty[:int(len(Left_images)*0.7)], Tz[:int(len(Left_images)*0.7)], Pitch[:int(len(Left_images)*0.7)], X[:int(len(Left_images)*0.7)], Y[:int(len(Left_images)*0.7)], Z[:int(len(Left_images)*0.7)]],\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    verbose=2,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]], [Fx[int(len(Left_images)*0.7):], Fy[int(len(Left_images)*0.7):], U0[int(len(Left_images)*0.7):], V0[int(len(Left_images)*0.7):], Baseline[int(len(Left_images)*0.7):], Disparity[int(len(Left_images)*0.7):], Tx[int(len(Left_images)*0.7):], Ty[int(len(Left_images)*0.7):], Tz[int(len(Left_images)*0.7):], Pitch[int(len(Left_images)*0.7):], X[int(len(Left_images)*0.7):], Y[int(len(Left_images)*0.7):], Z[int(len(Left_images)*0.7):]]),\n",
    "    callbacks=[tensorboard, checkpointer, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb7e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-19T06:01:49.104136Z",
     "iopub.status.busy": "2023-11-19T06:01:49.103788Z",
     "iopub.status.idle": "2023-11-19T06:02:24.554519Z",
     "shell.execute_reply": "2023-11-19T06:02:24.553712Z"
    },
    "papermill": {
     "duration": 35.479083,
     "end_time": "2023-11-19T06:02:24.557035",
     "exception": false,
     "start_time": "2023-11-19T06:01:49.077952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "#from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "#model.load_weights('/home/cv_lab/Downloads/CPL-A.h5')\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (150, 150, 3)\n",
    "\n",
    "\n",
    "output = model.predict(\n",
    "    x=[Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 44520\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0)\n",
    "            \n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3856687,
     "sourceId": 6733068,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3955483,
     "sourceId": 6933137,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29579.273775,
   "end_time": "2023-11-19T06:02:29.043566",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-18T21:49:29.769791",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
